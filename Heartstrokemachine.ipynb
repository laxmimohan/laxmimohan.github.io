{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this project we will build a Machine Learning model to predict whether an indiviudal will have a stroke.  The data used in this project can be found on kaggle at the following link: https://www.kaggle.com/asaumya/healthcare-data#train_2v.csv\n",
    "\n",
    "# In this notebook, we build and implement our Machine Learning model.  In our initial data analysis, we noticed that the individuals who had a stroke make up approximately 1.8% of the data.  We will use the Synthetic Minority Oversampling Technique (SMOTE) to account for this.\n",
    "\n",
    "# To view our initial data analysis, please see the notebook titled \"Data_Analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>children</td>\n",
       "      <td>smokes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>smokes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>other</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>smokes</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease ever_married work_type   smoking_status   age  \\\n",
       "0             0              0           No  children           smokes   3.0   \n",
       "1             1              0          Yes     other     never smoked  58.0   \n",
       "2             0              0           No     other           smokes   8.0   \n",
       "3             0              0          Yes     other  formerly smoked  70.0   \n",
       "4             0              0           No     other           smokes  14.0   \n",
       "\n",
       "   average_glucose_level   bmi  stroke  \n",
       "0                  95.12  18.0       0  \n",
       "1                  87.96  39.2       0  \n",
       "2                 110.89  17.6       0  \n",
       "3                  69.04  35.9       0  \n",
       "4                 161.28  19.1       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file path to our data\n",
    "stoke_data_relevant_features_and_label_file_path = os.path.join(\"..\", \"Data\", \"stroke_data_relevant_features_and_label.csv\")\n",
    "\n",
    "# Create dataframe from local csv file \n",
    "stroke_data_relevant_features_and_label = pd.read_csv(stoke_data_relevant_features_and_label_file_path)\n",
    "\n",
    "# Previe dataframe\n",
    "stroke_data_relevant_features_and_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>hypertension_0</th>\n",
       "      <th>hypertension_1</th>\n",
       "      <th>heart_disease_0</th>\n",
       "      <th>heart_disease_1</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>work_type_other</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  average_glucose_level   bmi  stroke  hypertension_0  hypertension_1  \\\n",
       "0   3.0                  95.12  18.0       0               1               0   \n",
       "1  58.0                  87.96  39.2       0               0               1   \n",
       "2   8.0                 110.89  17.6       0               1               0   \n",
       "3  70.0                  69.04  35.9       0               1               0   \n",
       "4  14.0                 161.28  19.1       0               1               0   \n",
       "\n",
       "   heart_disease_0  heart_disease_1  ever_married_No  ever_married_Yes  \\\n",
       "0                1                0                1                 0   \n",
       "1                1                0                0                 1   \n",
       "2                1                0                1                 0   \n",
       "3                1                0                0                 1   \n",
       "4                1                0                1                 0   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  work_type_other  \\\n",
       "0                        0                   1                0   \n",
       "1                        0                   0                1   \n",
       "2                        0                   0                1   \n",
       "3                        0                   0                1   \n",
       "4                        0                   0                1   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               0                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               1                            0   \n",
       "4                               0                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to one hot encoded data\n",
    "machine_ready_stroke_data = pd.get_dummies(stroke_data_relevant_features_and_label, columns=[\"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"smoking_status\"])\n",
    "machine_ready_stroke_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Maching Learning algorithms will we try out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import SMOTE to handle the imbalanced data issue\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features and label\n",
    "X = np.array(machine_ready_stroke_data.drop([\"stroke\"], axis=1))\n",
    "y = np.array(machine_ready_stroke_data[\"stroke\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following section, we will run a for-loop to examine what order of SMOTE, split, scale (<em>SSS order</em>) yields the best results.  We will ignore any SSS order that scales before it splits, as this could bias the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-f7dd6c6aa4c9>, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-f7dd6c6aa4c9>\"\u001b[1;36m, line \u001b[1;32m65\u001b[0m\n\u001b[1;33m    classifier = SVC=solverargument, multi_class=multi_class_argument)\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We want to determine which order of SMOTE, split, scale (SSS order) is best for this model\n",
    "# We will use the mean and stdev methods of the statistics library,\n",
    "# to find out which SSS order yields the highest average accuracy, and which order is the most stable (lowest standard deviation)\n",
    "from statistics import mean, stdev\n",
    "\n",
    "# Define variables holding the value for the each argument,\n",
    "# in order to easily change it in multiple places\n",
    "\n",
    "## SMOTE() parameters\n",
    "sampling_strategy_argument = 0.80\n",
    "k_neighbors_argument = 18\n",
    "SV\n",
    "## train_test_split() parameters\n",
    "test_size_argument = 0.15\n",
    "random_state_argument = 20\n",
    "\n",
    "#logistic regression parameters\n",
    "#solverargument;newton-cg, lbfgs, liblinear, sag, saga\n",
    "solverargument = \"saga\"\n",
    "#multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
    "multi_class_argument = \"ovr\"\n",
    "\n",
    "## DecionTreeClassifier() parameters\n",
    "# max_depth_argument = 100\n",
    "# max_leaf_nodes_argument = 200\n",
    "\n",
    "# For every iteration in the loop,\n",
    "# we will append the accuracy of the current SSS order to it's own distinct list\n",
    "# After the loop has finished, we will calculate the average of each list\n",
    "# The list with the highest average we will call \"the most accuracte (on average)\"\n",
    "# we will also calculate the standard deviation of each list\n",
    "# The list with the lowest standard deviation we will call \"the most stable\"\n",
    "SSS_order_1_list = []\n",
    "SSS_order_2_list = []\n",
    "SSS_order_3_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # Print the current iteration of the loop,\n",
    "    # in case we use a large number of iterations\n",
    "    print(f\"Iteration {i+1}\", \"\\n\")\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"1. SMOTE, split, scale\")\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_SMOTE_train_scaled = X_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_scaler.transform(X_SMOTE_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = SVC=solverargument, multi_class=multi_class_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_1 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 1\n",
    "    SSS_order_1_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "    \n",
    "####################################################################################################\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"2. split, SMOTE, scale\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = LogisticRegression(solver=solverargument, multi_class=multi_class_argument)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_2 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 2\n",
    "    SSS_order_2_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"3. split, scale, SMOTE\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = LogisticRegression(solver=solverargument, multiclass=multi_class_argument)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_3 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 3\n",
    "    SSS_order_3_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "    \n",
    "    # Print a long line with blank lines above and below,\n",
    "    # to easily see where one iteration of the loop ends, and the next starts\n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "    \n",
    "    # Increase the iterator by one\n",
    "    # so that the print statement at the beginning will show we're on the next iteration\n",
    "    i += 1\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Find the average accuracy of each SSS order,\n",
    "# and add each average to a list\n",
    "average_1 = mean(SSS_order_1_list)\n",
    "average_2 = mean(SSS_order_2_list)\n",
    "average_3 = mean(SSS_order_3_list)\n",
    "averages_list = [average_1, average_2, average_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest average accuracy\n",
    "if max(averages_list) == averages_list[0]:\n",
    "    most_accurate_order = 1\n",
    "    average_accuracy_greatest = averages_list[0]\n",
    "    \n",
    "elif max(averages_list) == averages_list[1]:\n",
    "    most_accurate_order = 2\n",
    "    average_accuracy_greatest = averages_list[1]\n",
    "    \n",
    "elif max(averages_list) == averages_list[2]:\n",
    "    most_accurate_order = 3\n",
    "    average_accuracy_greatest = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most accurate order (highest average accuracy) is order {most_accurate_order}, with an average accuracy of {average_accuracy_greatest}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Find the standard deviation of the accuracy of each SSS order,\n",
    "# and add each standard deviation to a list\n",
    "standard_deviation_1 = stdev(SSS_order_1_list)\n",
    "standard_deviation_2 = stdev(SSS_order_2_list)\n",
    "standard_deviation_3 = stdev(SSS_order_3_list)\n",
    "standard_deviations_list = [standard_deviation_1, standard_deviation_2, standard_deviation_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest standard deviation\n",
    "if min(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    most_stable_order = 1\n",
    "    lowest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    most_stable_order = 2\n",
    "    lowest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    most_stable_order = 3\n",
    "    lowest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most stable order (lowest standard deviation) is order {most_stable_order}, with a standard deviation of {lowest_standard_deviation}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Print a blank line to separate the lines showing us the \"best\" orders from the lines showing us the \"worst\" orders\n",
    "print()\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest average accuracy\n",
    "if min(averages_list) == averages_list[0]:\n",
    "    least_accurate_order = 1\n",
    "    average_accuracy_least = averages_list[0]\n",
    "    \n",
    "elif min(averages_list) == averages_list[1]:\n",
    "    least_accurate_order = 2\n",
    "    average_accuracy_least = averages_list[1]\n",
    "    \n",
    "elif min(averages_list) == averages_list[2]:\n",
    "    least_accurate_order = 3\n",
    "    average_accuracy_least = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least accurate order (least average accuracy) is order {least_accurate_order}, with an average accuracy of {average_accuracy_least}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest standard deviation\n",
    "if max(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    least_stable_order = 1\n",
    "    greatest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    least_stable_order = 2\n",
    "    greatest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    least_stable_order = 3\n",
    "    greatest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least stable order (highest standard deviation) is order {least_stable_order}, with a standard deviation of {greatest_standard_deviation}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We want to determine which order of SMOTE, split, scale (SSS order) is best for this model\n",
    "# We will use the mean and stdev methods of the statistics library,\n",
    "# to find out which SSS order yields the highest average accuracy, and which order is the most stable (lowest standard deviation)\n",
    "from statistics import mean, stdev\n",
    "\n",
    "# Define variables holding the value for the each argument,\n",
    "# in order to easily change it in multiple places\n",
    "\n",
    "## SMOTE() parameters\n",
    "sampling_strategy_argument = 0.80\n",
    "k_neighbors_argument = 18\n",
    "\n",
    "## train_test_split() parameters\n",
    "test_size_argument = 0.15\n",
    "random_state_argument = 20\n",
    "\n",
    "#logistic regression parameters\n",
    "#solverargument;newton-cg, lbfgs, liblinear, sag, saga\n",
    "solverargument = \"saga\"\n",
    "#multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
    "multi_class_argument = \"ovr\"\n",
    "\n",
    "## DecionTreeClassifier() parameters\n",
    "# max_depth_argument = 100\n",
    "# max_leaf_nodes_argument = 200\n",
    "\n",
    "# For every iteration in the loop,\n",
    "# we will append the accuracy of the current SSS order to it's own distinct list\n",
    "# After the loop has finished, we will calculate the average of each list\n",
    "# The list with the highest average we will call \"the most accuracte (on average)\"\n",
    "# we will also calculate the standard deviation of each list\n",
    "# The list with the lowest standard deviation we will call \"the most stable\"\n",
    "SSS_order_1_list = []\n",
    "SSS_order_2_list = []\n",
    "SSS_order_3_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # Print the current iteration of the loop,\n",
    "    # in case we use a large number of iterations\n",
    "    print(f\"Iteration {i+1}\", \"\\n\")\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"1. SMOTE, split, scale\")\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_SMOTE_train_scaled = X_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_scaler.transform(X_SMOTE_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = LogisticRegression(solver=solverargument, multi_class=multi_class_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_1 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 1\n",
    "    SSS_order_1_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "    \n",
    "####################################################################################################\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"2. split, SMOTE, scale\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = LogisticRegression(solver=solverargument, multi_class=multi_class_argument)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_2 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 2\n",
    "    SSS_order_2_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"3. split, scale, SMOTE\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the Logistic Regression Classifier\n",
    "    classifier = LogisticRegression(solver=solverargument, multi_class=multi_class_argument)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_3 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 3\n",
    "    SSS_order_3_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "    \n",
    "    # Print a long line with blank lines above and below,\n",
    "    # to easily see where one iteration of the loop ends, and the next starts\n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "    \n",
    "    # Increase the iterator by one\n",
    "    # so that the print statement at the beginning will show we're on the next iteration\n",
    "    i += 1\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Find the average accuracy of each SSS order,\n",
    "# and add each average to a list\n",
    "average_1 = mean(SSS_order_1_list)\n",
    "average_2 = mean(SSS_order_2_list)\n",
    "average_3 = mean(SSS_order_3_list)\n",
    "averages_list = [average_1, average_2, average_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest average accuracy\n",
    "if max(averages_list) == averages_list[0]:\n",
    "    most_accurate_order = 1\n",
    "    average_accuracy_greatest = averages_list[0]\n",
    "    \n",
    "elif max(averages_list) == averages_list[1]:\n",
    "    most_accurate_order = 2\n",
    "    average_accuracy_greatest = averages_list[1]\n",
    "    \n",
    "elif max(averages_list) == averages_list[2]:\n",
    "    most_accurate_order = 3\n",
    "    average_accuracy_greatest = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most accurate order (highest average accuracy) is order {most_accurate_order}, with an average accuracy of {average_accuracy_greatest}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Find the standard deviation of the accuracy of each SSS order,\n",
    "# and add each standard deviation to a list\n",
    "standard_deviation_1 = stdev(SSS_order_1_list)\n",
    "standard_deviation_2 = stdev(SSS_order_2_list)\n",
    "standard_deviation_3 = stdev(SSS_order_3_list)\n",
    "standard_deviations_list = [standard_deviation_1, standard_deviation_2, standard_deviation_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest standard deviation\n",
    "if min(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    most_stable_order = 1\n",
    "    lowest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    most_stable_order = 2\n",
    "    lowest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    most_stable_order = 3\n",
    "    lowest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most stable order (lowest standard deviation) is order {most_stable_order}, with a standard deviation of {lowest_standard_deviation}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Print a blank line to separate the lines showing us the \"best\" orders from the lines showing us the \"worst\" orders\n",
    "print()\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest average accuracy\n",
    "if min(averages_list) == averages_list[0]:\n",
    "    least_accurate_order = 1\n",
    "    average_accuracy_least = averages_list[0]\n",
    "    \n",
    "elif min(averages_list) == averages_list[1]:\n",
    "    least_accurate_order = 2\n",
    "    average_accuracy_least = averages_list[1]\n",
    "    \n",
    "elif min(averages_list) == averages_list[2]:\n",
    "    least_accurate_order = 3\n",
    "    average_accuracy_least = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least accurate order (least average accuracy) is order {least_accurate_order}, with an average accuracy of {average_accuracy_least}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest standard deviation\n",
    "if max(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    least_stable_order = 1\n",
    "    greatest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    least_stable_order = 2\n",
    "    greatest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    least_stable_order = 3\n",
    "    greatest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least stable order (highest standard deviation) is order {least_stable_order}, with a standard deviation of {greatest_standard_deviation}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 \n",
      "\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9607195620057356\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9775729646697389\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8308755760368663\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2 \n",
      "\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9582862605370644\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.978494623655914\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8387096774193549\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3 \n",
      "\n",
      "1. SMOTE, split, scale\n",
      "Accuracy: 0.9608064656296168\n",
      "2. split, SMOTE, scale\n",
      "Accuracy: 0.9789554531490016\n",
      "3. split, scale, SMOTE\n",
      "Accuracy: 0.8296466973886328\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "The most accurate order (highest average accuracy) is order 2, with an average accuracy of 0.9783410138248848\n",
      "The most stable order (lowest standard deviation) is order 2, with a standard deviation of 0.0007039286781806345\n",
      "\n",
      "The least accurate order (least average accuracy) is order 3, with an average accuracy of 0.8330773169482847\n",
      "The least stable order (highest standard deviation) is order 3, with a standard deviation of 0.004916314579039519\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We want to determine which order of SMOTE, split, scale (SSS order) is best for this model\n",
    "# We will use the mean and stdev methods of the statistics library,\n",
    "# to find out which SSS order yields the highest average accuracy, and which order is the most stable (lowest standard deviation)\n",
    "from statistics import mean, stdev\n",
    "\n",
    "# Define variables holding the value for the each argument,\n",
    "# in order to easily change it in multiple places\n",
    "\n",
    "## SMOTE() parameters\n",
    "sampling_strategy_argument = 0.80\n",
    "k_neighbors_argument = 18\n",
    "\n",
    "## train_test_split() parameters\n",
    "test_size_argument = 0.15\n",
    "random_state_argument = 20\n",
    "\n",
    "## RandomForestClassifier() parameters\n",
    "n_estimators_argument = 5\n",
    "max_depth_argument = 100\n",
    "max_leaf_nodes_argument = 200\n",
    "\n",
    "# For every iteration in the loop,\n",
    "# we will append the accuracy of the current SSS order to it's own distinct list\n",
    "# After the loop has finished, we will calculate the average of each list\n",
    "# The list with the highest average we will call \"the most accuracte (on average)\"\n",
    "# we will also calculate the standard deviation of each list\n",
    "# The list with the lowest standard deviation we will call \"the most stable\"\n",
    "SSS_order_1_list = []\n",
    "SSS_order_2_list = []\n",
    "SSS_order_3_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    # Print the current iteration of the loop,\n",
    "    # in case we use a large number of iterations\n",
    "    print(f\"Iteration {i+1}\", \"\\n\")\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"1. SMOTE, split, scale\")\n",
    "        \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_SMOTE, y_SMOTE = smote.fit_sample(X, y.ravel())\n",
    "    y_SMOTE = y_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_SMOTE_train, X_SMOTE_test, y_SMOTE_train, y_SMOTE_test = train_test_split(X_SMOTE, y_SMOTE, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_SMOTE_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_SMOTE_train_scaled = X_scaler.transform(X_SMOTE_train)\n",
    "    X_SMOTE_test_scaled = X_scaler.transform(X_SMOTE_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimators_argument, max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_SMOTE_train_scaled, y=y_SMOTE_train)\n",
    "    score = classifier.score(X_SMOTE_test_scaled, y_SMOTE_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_1 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 1\n",
    "    SSS_order_1_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "    \n",
    "####################################################################################################\n",
    "    \n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"2. split, SMOTE, scale\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "    X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "    \n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimators_argument, max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_2 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 2\n",
    "    SSS_order_2_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    # Print the SSS order so we can analyze which one is \"best\"\n",
    "    print(\"3. split, scale, SMOTE\")\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_argument, random_state=random_state_argument)\n",
    "    \n",
    "    # Create scaler for features\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Use SMOTE to handle class imbalance\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy_argument, k_neighbors=k_neighbors_argument)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_sample(X_train_scaled, y_train.ravel())\n",
    "    y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "    # Create, fit, and score the Decision Tree Classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimators_argument, max_depth=max_depth_argument, max_leaf_nodes=max_leaf_nodes_argument)\n",
    "    classifier = classifier.fit(X=X_train_scaled_SMOTE, y=y_train_SMOTE)\n",
    "    score = classifier.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Append the score the the SSS_order_3 list,\n",
    "    # So that we can determine the average accuracy and standard deviation of SSS order 3\n",
    "    SSS_order_3_list.append(score)\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Accuracy: {score}\")\n",
    "\n",
    "####################################################################################################\n",
    "    \n",
    "    # Print a long line with blank lines above and below,\n",
    "    # to easily see where one iteration of the loop ends, and the next starts\n",
    "    print()\n",
    "    print(100*\"-\")\n",
    "    print()\n",
    "    \n",
    "    # Increase the iterator by one\n",
    "    # so that the print statement at the beginning will show we're on the next iteration\n",
    "    i += 1\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Find the average accuracy of each SSS order,\n",
    "# and add each average to a list\n",
    "average_1 = mean(SSS_order_1_list)\n",
    "average_2 = mean(SSS_order_2_list)\n",
    "average_3 = mean(SSS_order_3_list)\n",
    "averages_list = [average_1, average_2, average_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest average accuracy\n",
    "if max(averages_list) == averages_list[0]:\n",
    "    most_accurate_order = 1\n",
    "    average_accuracy_greatest = averages_list[0]\n",
    "    \n",
    "elif max(averages_list) == averages_list[1]:\n",
    "    most_accurate_order = 2\n",
    "    average_accuracy_greatest = averages_list[1]\n",
    "    \n",
    "elif max(averages_list) == averages_list[2]:\n",
    "    most_accurate_order = 3\n",
    "    average_accuracy_greatest = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most accurate order (highest average accuracy) is order {most_accurate_order}, with an average accuracy of {average_accuracy_greatest}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Find the standard deviation of the accuracy of each SSS order,\n",
    "# and add each standard deviation to a list\n",
    "standard_deviation_1 = stdev(SSS_order_1_list)\n",
    "standard_deviation_2 = stdev(SSS_order_2_list)\n",
    "standard_deviation_3 = stdev(SSS_order_3_list)\n",
    "standard_deviations_list = [standard_deviation_1, standard_deviation_2, standard_deviation_3]\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest standard deviation\n",
    "if min(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    most_stable_order = 1\n",
    "    lowest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    most_stable_order = 2\n",
    "    lowest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif min(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    most_stable_order = 3\n",
    "    lowest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The most stable order (lowest standard deviation) is order {most_stable_order}, with a standard deviation of {lowest_standard_deviation}\")\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Print a blank line to separate the lines showing us the \"best\" orders from the lines showing us the \"worst\" orders\n",
    "print()\n",
    "\n",
    "# Use conditionals to determine which SSS order has the lowest average accuracy\n",
    "if min(averages_list) == averages_list[0]:\n",
    "    least_accurate_order = 1\n",
    "    average_accuracy_least = averages_list[0]\n",
    "    \n",
    "elif min(averages_list) == averages_list[1]:\n",
    "    least_accurate_order = 2\n",
    "    average_accuracy_least = averages_list[1]\n",
    "    \n",
    "elif min(averages_list) == averages_list[2]:\n",
    "    least_accurate_order = 3\n",
    "    average_accuracy_least = averages_list[2]\n",
    "\n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least accurate order (least average accuracy) is order {least_accurate_order}, with an average accuracy of {average_accuracy_least}\")\n",
    "        \n",
    "####################################################################################################\n",
    "\n",
    "# Use conditionals to determine which SSS order has the highest standard deviation\n",
    "if max(standard_deviations_list) == standard_deviations_list[0]:\n",
    "    least_stable_order = 1\n",
    "    greatest_standard_deviation = standard_deviations_list[0]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[1]:\n",
    "    least_stable_order = 2\n",
    "    greatest_standard_deviation = standard_deviations_list[1]\n",
    "    \n",
    "elif max(standard_deviations_list) == standard_deviations_list[2]:\n",
    "    least_stable_order = 3\n",
    "    greatest_standard_deviation = standard_deviations_list[2]\n",
    "    \n",
    "# Print a message showing which SSS order has the highest average accuracy, along with it's accuracy\n",
    "print(f\"The least stable order (highest standard deviation) is order {least_stable_order}, with a standard deviation of {greatest_standard_deviation}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a better idea of which SSS order is \"the best,\" we will try training and testing the model one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "    \n",
    "# Use SMOTE to handle class imbalance\n",
    "smote = SMOTE(sampling_strategy=0.2, k_neighbors=2)\n",
    "X_train_SMOTE, y_train_SMOTE = smote.fit_sample(X_train, y_train.ravel())\n",
    "y_train_SMOTE = y_train_SMOTE.reshape(-1,1)\n",
    "\n",
    "# Create scaler for features\n",
    "X_SMOTE_scaler = StandardScaler().fit(X_train_SMOTE)\n",
    "\n",
    "# Scale features\n",
    "X_train_SMOTE_scaled = X_SMOTE_scaler.transform(X_train_SMOTE)\n",
    "X_test_scaled = X_SMOTE_scaler.transform(X_test)\n",
    "\n",
    "# Create, fit, and score the Decision Tree Classifier\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=30, max_leaf_nodes=60)\n",
    "classifier = classifier.fit(X=X_train_SMOTE_scaled, y=y_train_SMOTE)\n",
    "score = classifier.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export out final model\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train_SMOTE)\n",
    "\n",
    "standard_scaler_export_file_path = os.path.join(\"..\", \"web_development\", \"standard_scaler.model\")\n",
    "joblib.dump(standard_scaler, standard_scaler_export_file_path)\n",
    "\n",
    "classifier_export_file_path = os.path.join(\"..\", \"web_development\", \"stroke_predictor.model\")\n",
    "pickle.dump(classifier, open(classifier_export_file_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "\n",
    "# feature_names = [\"age\",\n",
    "#                  \"average_glucose_levels\",\n",
    "#                  \"bmi\",\n",
    "#                  \"hypertension_0\",\n",
    "#                  \"hypertension_1\",\n",
    "#                  \"heart_disease_0\",\n",
    "#                  \"heart_disease_1\",\n",
    "#                  \"ever_married_No\",\n",
    "#                  \"ever_married_Yes\",\n",
    "#                  \"work_type_Self-employed\",\n",
    "#                  \"work_type_children\",\n",
    "#                  \"work_type_other\",\n",
    "#                  \"smoking_status_formerly_smoked\",\n",
    "#                  \"smoking_status_never_smoked\",\n",
    "#                  \"smoking_status_smokes\"\n",
    "#                 ]\n",
    "# class_names=[\"did_not_have_a_stroke\", \"had_a_stroke\"]\n",
    "\n",
    "# dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "#                       feature_names=feature_names,\n",
    "#                       class_names=class_names,  \n",
    "#                       filled=True, rounded=True,  \n",
    "#                       special_characters=True)\n",
    "# graph = graphviz.Source(dot_data)  \n",
    "# graph "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
